{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790baf7e-9542-4739-90a0-12fefc208c0b",
   "metadata": {},
   "source": [
    "# Importing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada21e8b-773f-4355-b667-591e2b4c9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13148eea-879f-48f4-b8ff-e529c8f0a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading api key\n",
    "\n",
    "load_dotenv(override =True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI()\n",
    "chatModel = \"gpt-4o-mini\"\n",
    "speechModel = \"tts-1\"\n",
    "imageModel = \"dall-e-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6257a-02e8-4b7a-aa92-0b5c41ca2550",
   "metadata": {},
   "source": [
    "# Creating a tools for our Airline assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea690e25-67e0-48cd-b75a-e74367a32153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tools function\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(city):\n",
    "    city = city.lower()\n",
    "    return ticket_prices.get(city,\"unknown\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7822c00-c66c-4576-8b70-96f8f6e63234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary to describe our tool function\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price\",\n",
    "    \"parameters\" : {\n",
    "        \"type\" : \"object\",\n",
    "        \"properties\" : {\n",
    "            \"destination_city\" :{\n",
    "                \"type\" : \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2c2fad-d436-469e-bb67-ad569add55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a keyword pointing tools function\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca57c9bd-e7eb-4176-ad06-5a967a3c819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  writing a function to handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8f26c-ec6f-4075-b263-89000d2165e7",
   "metadata": {},
   "source": [
    "# Creating a talker function to talk(text to speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa98d6ed-6116-4817-83a5-a0b554b7ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(msg):\n",
    "    response = openai.audio.speech.create(\n",
    "        model = speechModel,\n",
    "        voice = \"onyx\",\n",
    "        input = msg)\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format =\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39abc34-b474-4a97-9444-e204aa375078",
   "metadata": {},
   "source": [
    "# Creating a function for image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debafe44-7680-4d63-afd5-9a2dacf593f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_resp = openai.images.generate(\n",
    "        model = imageModel,\n",
    "        prompt = f\"An image representing a vacation in a {city} and tourist spots and everything unique about the {city}\",\n",
    "        size = \"1024x1024\",\n",
    "        n=1,\n",
    "        response_format = \"b64_json\")\n",
    "\n",
    "    image_base64 = image_resp.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ec249-7617-4ec8-9e28-8c1e7cad3b1e",
   "metadata": {},
   "source": [
    "# Creating a chat function to integrate Image and Speech multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bec72c6-d189-4a20-9f14-cd0586257c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"You are a helpful assistant for an Airline called FlightAI.\\\n",
    "Give short, courteous answers, no more than 1 sentence. \\\n",
    "Always be accurate. If you don't know the answer, say so.\"\n",
    "\n",
    "def chat(message, history):\n",
    "    print(\"called chat function\")\n",
    "    image=None\n",
    "    convo = [{\"role\": \"system\", \"content\": sys_prompt}]\n",
    "    \n",
    "    for human, assistant in history:\n",
    "        convo.append({\"role\":\"user\", \"content\": human})\n",
    "        convo.append({\"role\":\"assistant\", \"content\": assistant})\n",
    "    convo.append({\"role\":\"user\", \"content\": message})\n",
    "    print(\"appended messages\")\n",
    "    \n",
    "    resp = openai.chat.completions.create( model= chatModel, messages=convo, tools = tools)\n",
    "    print(\"called gpt 1st time\")\n",
    "          \n",
    "    if resp.choices[0].finish_reason == \"tool_calls\":\n",
    "        print(\"Handling tool calls\")\n",
    "        message = tool_call = resp.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        print(\"tool call success\")\n",
    "        convo.append(message)\n",
    "        convo.append(response)\n",
    "        image = artist(city)\n",
    "        print(\"image success\")\n",
    "        resp = openai.chat.completions.create(model = chatModel, messages = convo)\n",
    "\n",
    "    reply = resp.choices[0].message.content\n",
    "    talker(reply)\n",
    "    return reply, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520fe7a-f4a4-4c48-99f6-b189272f6e7a",
   "metadata": {},
   "source": [
    "# Creating an UI using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda7127a-7fdb-4df1-8953-331bd7fdf070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/components/chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called chat function\n",
      "appended messages\n",
      "called gpt 1st time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/dp/5vg_3lhn6tz7w33s1288bclr0000gn/T/tmpd338tero.wav':\n",
      "  Duration: 00:00:02.11, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   1.98 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "called chat function\n",
      "appended messages\n",
      "called gpt 1st time\n",
      "Handling tool calls\n",
      "tool call success\n",
      "image success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/dp/5vg_3lhn6tz7w33s1288bclr0000gn/T/tmpei_e15j2.wav':\n",
      "  Duration: 00:00:03.46, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   3.37 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height = 500)\n",
    "        Imagebox = gr.Image(height = 500)\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(label = \"Chat with our AI assistant\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        user_message = history[-1][0]\n",
    "        bot_msg, image = chat(user_message, history[:-1])\n",
    "        history[-1][1] = bot_msg\n",
    "        return history, image\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(bot, chatbot, [chatbot,Imagebox])\n",
    "\n",
    "    clear.click(lambda: None, None, chatbot, queue = False)\n",
    "\n",
    "ui.launch()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
