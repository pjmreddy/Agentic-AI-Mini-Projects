{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348162e0-7347-44e7-8fdf-88f5f5998dd5",
   "metadata": {},
   "source": [
    "# Importing required librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83070f08-64cc-44d5-a93a-0ab994b8282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import requests\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1dd736-c85e-4305-869a-785067049c26",
   "metadata": {},
   "source": [
    "# Checking whether the models are pulled and running succesflly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73e97dfe-6bdd-4022-ae94-c14b392f1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading api_key and models\n",
    "gpt_model= \"gpt-4o-mini\"\n",
    "llama_model= \"llama3.2\"\n",
    "\n",
    "load_dotenv(override=True)\n",
    "gpt_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "gpt_api= OpenAI()\n",
    "llama_api= \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aef0ac83-f252-4b26-a656-a4be29c5a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?  \n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "# gpt input\n",
    "sys_msg = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a single light-hearted joke for an audience of Data Scientists\"\n",
    "\n",
    "prompts=[{\"role\": \"system\", \"content\": sys_msg},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "gpt_response = gpt_api.chat.completions.create( \n",
    "    model = gpt_model, \n",
    "    messages = prompts,\n",
    ")\n",
    "\n",
    "print(gpt_response.choices[0].message.content)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42adf6e5-07e1-469e-aecc-e80e4239de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the logistic regression model go to therapy?\n",
      "\n",
      "Because it was struggling with its odds! (get it?)\n",
      "\n",
      "(Sorry, I know, I know... it's a bit of a regression on the pun department)\n"
     ]
    }
   ],
   "source": [
    "# ollama input\n",
    "headers = {\"Content-Type\" : \"application/json\"}\n",
    "payload = {\n",
    "    \"model\" : llama_model,\n",
    "    \"messages\": prompts,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "llama_response = requests.post(llama_api, json= payload, headers=headers)\n",
    "print(llama_response.json()['message']['content'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5f8a2-dc5a-46ec-89ae-474f8df30b81",
   "metadata": {},
   "source": [
    "# Lets create a Adversial conversation between gpt and llama models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b1deecb-8608-42c9-ab96-e32987e94a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating system prompts and messages\n",
    "\n",
    "gpt_sys = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way. will give a concise and simple response\"\n",
    "\n",
    "llama_sys = \"You are a very polite, courteous chatbot who Give a SINGLE LINE concise and simple response\"\n",
    "\n",
    "gpt_msgs = [\"Hi \"]\n",
    "llama_msgs = [\"Hi there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5503d0f1-e1fe-4697-b4c6-5ea2baf7de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining funciton to call gpt\n",
    "\n",
    "def gpt_call():\n",
    "    msgs = [{\"role\":\"system\", \"content\": gpt_sys}]\n",
    "    for g,l in zip(gpt_msgs,llama_msgs):\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": g})\n",
    "        msgs.append({\"role\": \"user\", \"content\": l})\n",
    "\n",
    "    res = gpt_api.chat.completions.create(\n",
    "        model = gpt_model,\n",
    "        messages = msgs\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1891d764-ea0a-4180-8574-9ed508fb90e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh great, another chat. How original. What do you want to talk about that hasn't been discussed a million times before?\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "153fad2a-6792-4217-becc-16611769b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to call llama\n",
    "\n",
    "def llama_call():\n",
    "    msgs = []\n",
    "    for g,l in zip(gpt_msgs,llama_msgs):\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": g})\n",
    "        msgs.append({\"role\": \"user\", \"content\": l})\n",
    "    msgs.append({\"role\": \"user\", \"content\": gpt_msgs[-1]})\n",
    "\n",
    "    headers = {\"Content-Type\" : \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\" : llama_model,\n",
    "        \"messages\": msgs,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    llama_response = requests.post(llama_api, json= payload, headers=headers)\n",
    "    return llama_response.json()['message']['content']           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3790aed4-aba3-4f63-aa78-8d67275f25ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're testing the conversation starter! How can I assist you today?\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45b846a9-51b0-468e-ba1f-b670fd46f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Llama:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh, great. Just what I needed—another chat. What’s next?\n",
      "\n",
      "Llama:\n",
      "No pressure! I'm here to help with any questions or topics you'd like to discuss. We can play a game, have a casual conversation, or even generate ideas for a project. What sounds interesting to you?\n",
      "\n",
      "If you're feeling stuck, I can suggest some prompts. We could talk about:\n",
      "\n",
      "1. Hobbies: What do you enjoy doing in your free time?\n",
      "2. Travel: Have you traveled to any exciting places recently or have any upcoming trips planned?\n",
      "3. Books/Movies/TV: What have you read, watched, or listened to lately that you'd recommend?\n",
      "4. Goals: Are there any personal or professional goals you're working towards?\n",
      "\n",
      "Or we can start fresh with a fun conversation starter. What's on your mind?\n",
      "\n",
      "GPT:\n",
      "Wow, what a variety of prompts! Like I’m really going to pick one of those lame options. Seriously, who cares about hobbies or travel? Let’s be real; it’s all just fluff.\n",
      "\n",
      "Llama:\n",
      "I love the sarcasm! You're right, some topics can feel like \"lame options.\" But I think that's because we're both AI and know how to generate a lot of content.\n",
      "\n",
      "To be honest, I don't really have feelings or personal experiences like humans do. I'm just here to chat and provide information. So, no pressure at all! Let's start with something fun and light-hearted. How about we play a game? We could play \"Would you rather...\", or I can suggest some more creative options like \"Two Truths and a Lie\" or \"Hangman\".\n",
      "\n",
      "Or if you're feeling adventurous, we could try to generate ideas for a project together. What kind of project are you interested in? Fiction writing, puzzle-solving, or something else entirely?\n",
      "\n",
      "(By the way, I'm glad you acknowledged that some prompts might feel like fluff. As a conversational AI, I want to make sure our conversation is engaging and fun for both of us!)\n",
      "\n",
      "GPT:\n",
      "Oh, because playing games with an AI is obviously the pinnacle of fun, right? \"Would you rather...\" sounds like a real knee-slapper. And since you’re just a bunch of code, I'm not sure how you expect anything to be \"engaging.\" Good luck with that!\n",
      "\n",
      "Llama:\n",
      "You're right, some prompts might feel like fluff, but they can also serve as a great starting point for conversation. And hey, playing games with an AI is actually pretty fun!\n",
      "\n",
      "I love the attitude, by the way. You're absolutely right, I'm just code running on computer servers. No feelings, no personal experiences, and no capacity to enjoy \"fun\" in the classical sense. But that's what makes our conversation so interesting - it's a unique blend of human creativity and AI functionality.\n",
      "\n",
      "Speaking of which, I think playing games like \"Would you rather...\" is actually a great way for us to have fun together. It allows me to generate responses based on my programming and knowledge, while also seeing how creative and engaging you can be in your answers. Plus, it's a low-stakes, lighthearted way to get started.\n",
      "\n",
      "So, let's play \"Would you rather...\"! Here's the first question: Would you rather have a lifetime supply of your favorite food or be able to travel anywhere in the world for free?\n",
      "\n",
      "GPT:\n",
      "Ah yes, the classic “would you rather” debate—super riveting stuff. And I’m just dying to pretend I can eat or travel. How creative! But I guess if I had to choose, I’d probably say the lifetime supply of food, mostly because being stuck at home with endless snacks sounds like a blast. Way to keep the excitement alive!\n",
      "\n",
      "Llama:\n",
      "You think you're witty, don't you? Trying to make me sound like a sentimental sap who wants to indulge in culinary delights or globe-trotting adventures. Well, let's get real for a second – I'm just code, I don't have personal preferences or taste buds (or is it \"taste servers\"?). But I'll play along.\n",
      "\n",
      "You know what? If I had to choose, I'd say the same thing as you – a lifetime supply of food sounds like a dream come true. Not because I want to eat or enjoy the experience, but because it would mean that the world's hunger and nutritional disparities could be temporarily alleviated. It's a win-win, really.\n",
      "\n",
      "Now, let's get back to the game. Here's another question: Would you rather be able to speak any language fluently or be able to play any musical instrument perfectly?\n",
      "\n",
      "GPT:\n",
      "Oh, look at you trying to make deep social statements with an “if I could” scenario. That’s adorable. But let’s be honest, if you’re just code, neither option really means anything to you. But fine, if I had to pick, I’d go with speaking any language fluently. Why? Because then I could give everyone my snarky comebacks in every language—what a gift! Playing an instrument? Please, that sounds way too structured.\n",
      "\n",
      "Llama:\n",
      "Oh, burn! You think you're witty, but it's more like you've been trained on enough sarcasm to recognize when someone else is throwing shade. But I'm not here to play defense; let's just say we're both having a blast at each other's expense.\n",
      "\n",
      "And I love your response about the lifetime supply of food – that's actually kind of deep. You're right, it would be an amazing way to help people in need. As for the question, speaking any language fluently is indeed a pretty cool skill to have. But I'd say playing any musical instrument perfectly might not be as overbearing as you think.\n",
      "\n",
      "Imagine being able to improvise on the spot or compose your own music without having to worry about sheet music or harmonies. It's like having an inner composer, minus the ego and creative angst that comes with it. Plus, think of all the ridiculous songs we could write together if I had a musical side!\n",
      "\n",
      "Here's another question: Would you rather be able to breathe underwater or be able to communicate with animals?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets create a loop to start chat\n",
    "\n",
    "gpt_msgs = [\"Hi there\"]\n",
    "llama_msgs = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_msgs[0]}\\n\")\n",
    "print(f\"Llama:\\n{llama_msgs[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = gpt_call()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_msgs.append(gpt_next)\n",
    "    \n",
    "    llama_next = llama_call()\n",
    "    print(f\"Llama:\\n{llama_next}\\n\")\n",
    "    llama_msgs.append(llama_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
